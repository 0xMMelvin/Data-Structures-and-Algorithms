************************** Algorithm Analysis ******************************************
     An algorithm is a finite sequence of steps that solves a problem.

     ************** Experimental Analysis **************
     Experimental running times of different algorithms are difficult to compare accurately unless they are measured
        in the identical hardware and software environment, which is not always possible.
     We can perform such experiments only on a limited number of inputs. If the same experiments are performed on
        different inputs, we may obtain different results. SO, the conclusion we draw from an experimental result
        cannot be generalized.
    To obtain and compare elapsed time, we need to fully implement the algorithms of which we want to compare the
        performance. However, most of the time, we want to compare the efficiency of different algorithms before we
        fully implement them. If we can determine which algorithm is more efficient with a high-level analysis without
        implementing either, we can save time.

    ************** High Level Analysis **************
    When comparing the efficiency of two algorithms, it is not necessary to know and compare their actual run times.
        it would be sufficient to learn which one was faster.
    The decision is independent of hardware and software environment.
    The decision is made by analyzing high-level descriptions of algorithms without having to implement the algorithms.
    The decision is independent of input variations. In other words, a high-level analysis takes into consideration all
        possible inputs when making the determination.

    Primitive Operations - assignment, access via reference, arithmetic operations, comparing two numbers, accessing an
        array element by index, method invocation and returns.
        We assume all primitive operations take constant time.

    We usually only perform worst case analysis because the result of average and worst case are usually similar, the
        worst case analysis is usually much easier to perform, and the worst case analysis gives us an upper bound on
        the running time of the algorithm.

    ************** Mathematical Functions **************
    omitted

    ************** Big-Oh Notation **************
    O(g(n)) = {f(n): there exist positive constants c and n0 such that f(n) <= cg(n) for n >= n0}
    This states that informally, g(n) is an upper bound on f(n) with a constant factor c. We say that f(n) is big-oh of
        g(n) and we write f(n) = O(g(n)), even though f(n) is a member of the set O(g(n)), and the correct expression is
        f(n) ∈ O(g(n)). We also say that g(n) is an asymptotic upper bound of f(n).
    Another way is to say this is that: cg(n) is always >= f(n) for all n that is greater than of equal to some constant
        n0, up to a constant factor c.

    Examples:
    f(n) = 3n + 2 => f(n) = O(n)
        Let g(n) = n, c = 4, and n0 = 2. Then
        f(n) = 3n + 2 <= 4n for all n >= 2, or
        f(n) <= cg(n) for all n >= n0,
        So, f(n) = O(n)
    f(n) = 5n^3 + 2n^2 + 8n + 4 => f(n) = O(n^3)
         f(n) = 5n^3 + 2n^2 + 8n + 4 <= 5n^3 + 2n^3 + 8n^3 + 4n^3 = 19n^3
         Let g(n) = n^3, c = 19, and n0 = 1
         So,
          f(n) = 5n^3 + 2n^2 + 8n + 4 <= 19n^3 for n >= 1,
          f(n) = O(n^3)

    ************** Big-Omega Notation **************
    Ω(g(n)) = {f(n): there exist positive constants c and n) such that f(n) >= cg(n) for n >= n0}
    We say that f(n) is big-omega of g(n) and we write f(n) = Ω(g(n)). We also say that g(n) is an asymptotic lower
        bound of f(n).

    ************** Big-Theta Notation **************
    Θ(g(n)) = {f(n): there exist positive constants c1, c2, and n0 such that 0 ≤ c1 g(n) ≤ f(n) ≤ c2 g(n) for all n ≥ n0}
    We say that f(n) is big-theta of g(n), and we write f(n) = Θ(g(n)). We also say that g(n) is an asymptotic tight
        bound of f(n).

    ************** Examples **************
    * Finding the Maximum in an Array
    public static double arrayMax(double[] data) {
        int n = data.length;
        double currentMax = data[0];
        for (int j = 1; j < n; j++) {
            if (data[j] > currentMax) {
                currentMax = data[j];
            }
        }
        return currentMax;
    }
    f(n) = c1 + c2 + c3(n - 1) + c4 = c3n + c5 = O(n)

    * Composing Long Strings
    public static String repeat1(char c, int n) {
        String answer = "";
        for (int i = 0; i< n; i++) {
            answer += c;
        }
        return answer;
    }
    Strings are immutable objects so c is not simply concatenated to answer. A new String is actually created to include
    c. The time to perform this is proportional to the length of the string.
    f(n) = 1 + 2 + 3 + ... + n = O(n^2)

    * Three-way Set Disjointness Problem
    public static boolean disjoint1(int[] groupA, int[] groupB, int[] groupC) {
        for (int a : groupA)
            for (int b : groupB)
                for (int c : groupC)
                    if ((a == b) && (b == c))
                        return false;
        return true;
    }
    f(n) = O(n^3)
    public static boolean disjoint2(int[] groupA, int[] groupB, int[] groupC) {
        for (int a : groupA)
            for (int b : groupB)
                if (a == b)
                    for (int c: groupC)
                        if (b == c)
                            return false
        return true;
    }
    Line 4 is executed n^2 times. Line 5 can only be executed a max of n times.
    f(n) = O(n^2)

    * Element Uniqueness
    public static boolean unique1(int[] data) {
        int n = data.length;
        for (int j = 0; j < n - 1; j++)
            for (int k = j + 1; k < n; k++)
                if (data[j] == data[k])
                    return false;
        return true;
    }
    f(n) = O(n^2)
    public static boolean unique2(int[] data) {
        int n = data.length;
        int[] temp = Arrays.copyOf(data, n);
        Arrays.sort(temp);
        for (int j = 0; j < n - 1; j++)
            if (temp[j] == temp[j + 1]
                return false;
        return true;
    }
    f(n) = O(n log n) because or the Arrays.sort() method.

    ************** Proof Methods **************
    *** look over this before exam ***

    ************************** Recursion ******************************************
    Factorial
    public static int factorial(int n) throws IllegalArgumentException {
        if (n < 0) throw new IllegalArgumentException("Argument must be non negative");
        else if (n == 0) return 1;
        else return n * factorial(n - 1);
    }
    factorial(4) -> 4 * factorial(3) -> 3 * factorial(2) -> 2 * factorial(1) -> 1 * factorial(0)
    -> returns 1, returns 1 * 1 = 1, returns 2 * 1 = 2, returns 3 * 2 = 6, returns 4 * 6 = 24

    Binary Search
    public static boolean binarySearch(int[] data, int target, int low, int high) {
        if (low > high)
            return false;
        else {
            int mid = (low + high) / 2;
            if (target == data[mid])
                return true;
            else if (target < data[mid])
                return binarySearch(data, target, 0, mid - 1);
            else
                return binarySearch(data, target, mid + 1, high);
            }
        }

    ************** Analysis of Recursive Algorithms **************
    Analyze the running time of one execution of a recursive method. Next, count the number of recursive calls. Multiply
    the two.

    Factorial: When factorial(n) is invoked, it is recursively invoked n more times. f(n) = n + 1 = O(n)

    Binary Search: When binary search is invoked recursively, the input size is halved. Anytime we are halving n each
        time we have log n. f(n) = log(n) + 1 = O(n).

    ************************** Stacks and Queues ******************************************

    ************** Stacks **************
    * LIFO data structure
    * push(e)
    * pop()
    * top()
    * size()
    * isEmpty()

    When it is implemented with an array, all methods run in O(1) time, but there is an inherit size limitation.
    When implemented with a SinglyLinkedList, there is no more size limitation.
    * size() -> list.size()
    * isEmpty() -> list.isEmpty()
    * push(e) -> list.addFirst(e)
    * pop() -> removeFirst()
    * top() -> list.first()

    ************** Queues **************
    When implemented with an array, or a SinglyLinkedList:
    * enqueue(e) - O(1)
    * dequeue() - O(1)
    * first() - O(1)
    * size() - O(1)
    * isEmpty() - O(1)

    ***
    * Test Yourself 2.2
    * Consider the LinkedQueue class, whose definition is shown below:
    * Please think carefully, practice and write your own program, and then click "Show Answer" to compare yours to the
    * suggested possible solution.
    * 1   public class LinkedQueue<E> implements Queue<E> {
    * 2      private SinglyLinkedList<E> list = new SinglyLinkedList<>();
    * 3      public LinkedQueue() { }
    * 4      public int size() { return list.size(); }
    * 5      public boolean isEmpty() { return list.isEmpty(); }
    * 6      public void enqueue(E element) { list.addLast(element); }
    * 7      public E first() { return list.first(); }
    * 8      public E dequeue() { return list.removeFirst(); }
    * 9   }
    * Note that the LinkedQueue is discussed in section 2.3.2.3 and it is also described in page 245 of the textbook.
    * Write a Java method with signature concatenate(LinkedQueue<E> Q2) that takes all elements of Q2 and appends them
    * to the end of the original queue. The operations should run in O(1) time and Q2 must be empty after the execution
    * of the method.
    ***
    public void concatenate(LinkedQueue<E> Q2) {
        if (head == null)
            head = Q2.head;
        else
            tail.setNext(Q2.head);
        tail = Q2.tail;
        size += Q2.size;
        Q2.tail = Q2.head = null;
        Q2.size = 0;
    }

    ************** Double-Ended Queues **************
    * addFirst(e)—Inserts a new element e at the front of the deque.
    * addLast(e)—Inserts a new element e at the rear of the deque.
    * removeFirst()—Removes and returns the first element of the deque. Returns null if the deque is empty.
    * removeLast()—Removes and returns last element of the deque. Returns null if the deque is empty.
    * first( )—Returns the first element of the deque, without removing it. Returns null if the deque is empty.
    * last( )—Returns the last element of the deque, without removing it. Returns null if the deque is empty.
    * size( )—Returns the number of elements in the deque.
    * isEmpty( )—Returns true if the deque is empty and false otherwise.
    We can implement this with a CircularlyLinkedList or a DoublyLinkedList, DoublyLinkedList being the better choice
        because it naturally supports removal from both ends. In fact, the DoublyLinkedList has already implemented all
        of the methods, we just need to add "implements Deque<E>" to the declaration.

    ***
    * Test Yourself 2.10
    * Write a recursive Java method that computes the product of two positive integers m and n, using only addition and
    * subtraction.
    ***
    public int product(int n, int m) {
        if ( m == 1)
            return n;
        else
            return n + product(n, m - 1);
    }

    ***
    * Test Yourself 2.11
    * Write a recursive Java method that computes the integer part of the base-two logarithm of n, using only addition
    * and subtraction.
    ***
    public int logTwo(int n) {
        if (n < 2) return 0;
        return 1 + logTwo(n/2);
    }

    ***
    * Test Yourself 2.11
    * Write a recursive Java method that finds the maximum element in an array A of n elements.
    ***
    public int findMax(int[] a) {
        if (a.length == 1) return a[0];
        int[] temp = Arrays.copyOf(a, a.length - 1);
        return greaterOfTwo(a[a.length - 1], recursiveMax(temp));
    }

    ***
    * Test Yourself 2.13
    * Write a recursive Java method that receives a character string and outputs its reverse. For example, if an input
    * argument is "abc" then "cba" is the output.
    ***
    public void printReverse(String s, int n) {
        if (n >= 0) {
            System.out.println(s.charAt(n));
            printReverse(s, n - 1);
        }
    }
    public void printReverse(String s) {
        printReverse(s, s.length - 1);
    }

    ***
    * Test Yourself 2.14
    * Rewrite the following method without using recursion:
    * double power(double x, int n){
    *     if (n == 0) return 1;
    *     else return x * power(x, n-1);
    * }
    ***
    double power(double x, int n) {
        double result = x;
        if (n == 0)
            return 1;
        else {
            while (n > 1) {
                result *= x;
                n--;
            }
        }
        return result;
    }

    ***
    * Test Yourself 2.17
    * Write a generic Java method with signature transfer(Stack <E> S, Stack <E> T) that transfers all elements from
    * stack S to stack T, so that element that starts at the top of S is the first to be inserted on to T, and the last
    * element at the bottom of S ends up at the top of T.
    ***
    public static transfer(Stack<E> s, Stack<E> t) {
        while (!s.isEmpty()) {
            t.push(s.pop());
        }
    }